{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Welcome to the XAI Toolkit \ud83d\ude4b\u200d\u2640\ufe0f A short introduction This organization has been created in order to host many different repos that are related to Explainable AI (XAI). Each repository contains a different algorithm along with information and different studies that it was used in. \ud83d\udc69\u200d\ud83d\udcbb Useful resources Each repository contains a README file along with an MkDocs configuration, with all the information about their algorithm.","title":"Home"},{"location":"#welcome-to-the-xai-toolkit","text":"","title":"Welcome to the XAI Toolkit"},{"location":"#a-short-introduction","text":"This organization has been created in order to host many different repos that are related to Explainable AI (XAI). Each repository contains a different algorithm along with information and different studies that it was used in.","title":"\ud83d\ude4b\u200d\u2640\ufe0f A short introduction"},{"location":"#useful-resources","text":"Each repository contains a README file along with an MkDocs configuration, with all the information about their algorithm.","title":"\ud83d\udc69\u200d\ud83d\udcbb Useful resources"},{"location":"archetypal-analysis-toolbox/","text":"TDBenchmarker Source code of the TD Benchmarker tool. The tool is hosted here . TD Benchmarker toolbox is an interactive web-based application implemented using Shiny framework taking advantage of the R statistical language in an easy-to-use frontend. The toolbox supports a fully automated investigation of the degree of agreement between three leading TD assessment tools. Moreover, TD Benchmarker provides a general framework to capture the diversity of the examined tools with the aim of identifying few 'reference assessments' representing different profiles of classes with respect to their TD levels. After the characterization of the derived reference assessments, the goal is to extract a set of classes presenting high similarity to the Max-Ruler reference assessment. The Max Ruler reference assessment represents the profile of classes accumulating high amount of TD based on the results of all applied tools. The core methodology of the toolbox is Archetypal Analysis, which is a statistical methodology that explores the multidimensional space with the aim of identifying certain points, namely the archetypes, located on the boundaries of a swarm of given points, known as their convex hull. TD Benchmarker is ready to report the results derived from the analysis on TD assessments provided by the application of three leading TD assessement tools (Sonar, Squore, Cast) through a benchmark experiment of 25 Java and 25 JS OSS projects with a fully automated manner offering: Report on the degree of agreement of the applied tools with respect to the measured TD of classes. Identification of few reference TD assessments. Extraction of a benchmark of high-TD classes based on the agreement of all TD tools.","title":"TD Benchmarker"},{"location":"archetypal-analysis-toolbox/#tdbenchmarker","text":"Source code of the TD Benchmarker tool. The tool is hosted here . TD Benchmarker toolbox is an interactive web-based application implemented using Shiny framework taking advantage of the R statistical language in an easy-to-use frontend. The toolbox supports a fully automated investigation of the degree of agreement between three leading TD assessment tools. Moreover, TD Benchmarker provides a general framework to capture the diversity of the examined tools with the aim of identifying few 'reference assessments' representing different profiles of classes with respect to their TD levels. After the characterization of the derived reference assessments, the goal is to extract a set of classes presenting high similarity to the Max-Ruler reference assessment. The Max Ruler reference assessment represents the profile of classes accumulating high amount of TD based on the results of all applied tools. The core methodology of the toolbox is Archetypal Analysis, which is a statistical methodology that explores the multidimensional space with the aim of identifying certain points, namely the archetypes, located on the boundaries of a swarm of given points, known as their convex hull. TD Benchmarker is ready to report the results derived from the analysis on TD assessments provided by the application of three leading TD assessement tools (Sonar, Squore, Cast) through a benchmark experiment of 25 Java and 25 JS OSS projects with a fully automated manner offering: Report on the degree of agreement of the applied tools with respect to the measured TD of classes. Identification of few reference TD assessments. Extraction of a benchmark of high-TD classes based on the agreement of all TD tools.","title":"TDBenchmarker"},{"location":"binary-classification-toolbox/","text":"TD Classifier Description This repository contains the source code of the TD Classifier back-end ( video , running instance ). TD Classifier is a novel tool that employs Machine Learning (ML) for classifying software classes as High/Not-High TD for any arbitrary Java project, just by pointing to its git repository. It has been developed as part of our recent research work ( Tsoukalas et al., 2021 ) towards demonstrating the usefulness of the proposed classification framework in practice. As ground truth for the development of the tool's classification framework, we considered a \"commonly agreed TD knowledge base\" ( Amanatidis et al., 2020 ), i.e., an empirical benchmark of classes that exhibit high levels of TD, based on the convergence of three widely-adopted TD assessment tools, namely SonarQube , CAST , and Squore . Then, we built a set of independent variables based on a wide range of software metrics spanning from code metrics to repository activity, retrieved by employing four popular open source tools, namely PyDriller , CK , PMD\u2019s Copy/Paste Detector , and cloc . Therefore, the tool subsumes the collective knowledge that would be extracted by combining the results of the three TD assessment tools and relies on four open-source tools to automatically retrieve all independent variables and yield the identified high-TD classes. In that way, it enables identification and further experimentation of high-TD modules, without having to resort to a multitude of commercial and open source tools. Note : the source code of the TD Classifier frontend is also publicly available as part of the overall SDK4ED Dashboard and can be found here . Installation Installation using Anaconda In this section, we provide instructions on how the user can build the python Flask server of the TD Classifier from scratch, using the Anaconda virtual environment. The TD Classifier is developed to run on Unix and Windows systems with python 3.6.* innstalled. We suggest installing python via the Anaconda distribution as it provides an easy way to create a virtual environment and install dependencies. The configuration steps needed, are described below: Step 1 : Download the latest Anaconda distribution and follow the installation steps described in the Anaconda documentation . Step 2 : Open Anaconda cmd. Running Anaconda cmd activates the base environment. We need to create a specific environment to run TD Classifier backend. Create a new python 3.6.4 environment by running the following command: conda create --name td_classifier python=3.6.4 This command will result in the creation of a conda environment named td_classifier . In order to activate the new environment, execute the following command: conda activate td_classifier Step 3 : Once your newly created environment is active, install the needed libraries by executing the following commands: conda install -c anaconda numpy pandas scikit-learn waitress flask flask-cors requests pymongo conda install -c conda-forge gitpython and pip install pydriller Step 4 : To start the server, use the command promt inside the active environment and execute the commands described in section Run Server . Installation using Docker (recommended) In this section, we provide instructions on how the user can build a new Docker Image that contains the python Flask app and the Conda environment of the of the TD Classifier. We highly recommend the users to select this way of installing the TD Classifier, as it constitutes the easiest way. Step 1 : Download and install Docker Step 2 : Clone the latest TD Classifier version and navigate to the home directory. You should see a DockerFile and a environment.yml file, which contains the Conda environment dependencies. Step 3 : In the home directory of the TD Classifier, open cmd and execute the following command: sudo docker build -t td_classifier_image . This command will result in the creation of a Docker Image named td_classifier_image . In order to create a Docker Container from this image, execute the following command: sudo docker run -it --name td_classifier_test -p 5005:5005 td_classifier_image This command will generate and run a Docker Container named td_classifier_test in interactive session mode, i.e. it will open a command promt inside the Container. - Step 4 : To start the server, use the command promt inside the running Container and execute the commands described in section Run Server . Installation of the Database A MongoDB database dedicated to storing the output of the TD Classifier web service allows the tool to quickly retrieve past results upon demand, without having to go through the time-consuming process of re-executing the analysis process. TD Classifier does not require a running database instance to be functional. However, in case you require access to previously produced results, a database dedicated to store the output of the TD Classifier web services might be of help. In that case, MongoDB is a well-suited option for the purposes of the TD Classifier. To quickly install a MongoDB using Docker, open cmd and execute the following command: sudo docker run --detach \\ -p 27017:27017 \\ --name mongodb \\ --volume /home/<user_name>/Desktop/mongo_data:/data/db \\ mongo This command will generate and run a MongoDB Docker Container named mongodb , which will serve as the TD Classifier's dedicated DB. Run Server You can run the server in various modes using Python to run the td_classifier_service.py script: usage: td_classifier_service.py [-h] [-dh DB_HOST] [-dp DB_PORT] [-dn DB_DBNAME] [--debug] HOST PORT SERVER_MODE positional arguments: HOST Server HOST (e.g. \"localhost\") PORT Server PORT (e.g. \"5005\") SERVER_MODE builtin, waitress optional arguments: -h, --help show this help message and exit -dh DB_HOST MongoDB HOST (e.g. \"localhost\") (default: localhost) -dp DB_PORT MongoDB PORT (e.g. \"27017\") (default: 27017) -dn DB_DBNAME Database NAME (default: td_classifier_service) --debug Run builtin server in debug mode (default: False) HOST , PORT , and SERVER_MODE arguments are mandatory . You can set them according to your needs. DB_HOST , DB_PORT , and DB_DBNAME arguments are optional and assume that there is a MongoDB instance running either on a local machine or remotely. In case that there is no such MongoDB instance running, the TD Classifier will still return the results, but they will not be stored anywhere. Run built-in Flask server 127.0.0.1:5005 Client <----------------> Flask To start the TD Classifier using the built-in Flask server, use the command promt inside the active Conda or Container environment and execute the following command: python td_classifier_service.py 0.0.0.0 5005 builtin --debug This command will start the built-in Flask server locally (0.0.0.0) on port 5005. MongoDB Integration In case there is a MongoDB instance running, use the command promt inside the active conda or Container environment and execute the following command: python td_classifier_service.py 0.0.0.0 5005 waitress -dh 160.40.52.130 -dp 27017 -dn td_classifier_service This command will start the built-in Flask server locally on port 5005 and store the results on a MongoDB database named \"td_classifier_service\" running locally on port 27017. Warning : The built-in Flask mode is useful for development since it has debugging enabled (e.g. in case of error the client gets a full stack trace). However, it is single-threaded. Do NOT use this mode in production! Run Waitress server 127.0.0.1:5005 Client <----------------> Waitress <---> Flask To start the TD Classifier using the Waitress server, use the command promt inside the active Conda or Container environment and execute the following command: python td_classifier_service.py 0.0.0.0 5005 waitress This command will start the Waitress server locally (0.0.0.0) on port 5005. MongoDB Integration In case there is a MongoDB instance running, use the command promt inside the active conda or Container environment and execute the following command: python td_classifier_service.py 0.0.0.0 5005 waitress -dh 160.40.52.130 -dp 27017 -dn td_classifier_service This command will start the Waitress server locally on port 5000 and store the results on a MongoDB database named \"td_classifier_service\" running locally on port 27017. Warning : The Waitress mode is higly recommended in real production environments, since it supports scaling and multiple-request handling features. Next Steps Once the server is up and running, you can either exploit the TD Classifier APIs directly via requests, or setup the SDK4ED platform locally (see here ) to benefit from the already implemented and user-friendly TD Classifier frontend. How to cite? A paper introducing the TD Classifier tool has been published in the Proceedings of the International Conference on Technical Debt (TechDebt '22) . To cite this work, please use the following bibtex entry: @inproceedings{tsoukalas2022td, author = {Tsoukalas, Dimitrios and Chatzigeorgiou, Alexander and Ampatzoglou, Apostolos and Mittas, Nikolaos and Kehagias, Dionysios}, title = {TD Classifier: Automatic Identification of Java Classes with High Technical Debt}, year = {2022}, publisher = {Association for Computing Machinery}, address = {New York, NY, USA}, doi = {10.1145/3524843.3528094}, booktitle = {Proceedings of the International Conference on Technical Debt}, pages = {76\u201380}, numpages = {5}, location = {Pittsburgh, Pennsylvania}, series = {TechDebt '22} }","title":"TD Classifier"},{"location":"binary-classification-toolbox/#td-classifier","text":"","title":"TD Classifier"},{"location":"binary-classification-toolbox/#description","text":"This repository contains the source code of the TD Classifier back-end ( video , running instance ). TD Classifier is a novel tool that employs Machine Learning (ML) for classifying software classes as High/Not-High TD for any arbitrary Java project, just by pointing to its git repository. It has been developed as part of our recent research work ( Tsoukalas et al., 2021 ) towards demonstrating the usefulness of the proposed classification framework in practice. As ground truth for the development of the tool's classification framework, we considered a \"commonly agreed TD knowledge base\" ( Amanatidis et al., 2020 ), i.e., an empirical benchmark of classes that exhibit high levels of TD, based on the convergence of three widely-adopted TD assessment tools, namely SonarQube , CAST , and Squore . Then, we built a set of independent variables based on a wide range of software metrics spanning from code metrics to repository activity, retrieved by employing four popular open source tools, namely PyDriller , CK , PMD\u2019s Copy/Paste Detector , and cloc . Therefore, the tool subsumes the collective knowledge that would be extracted by combining the results of the three TD assessment tools and relies on four open-source tools to automatically retrieve all independent variables and yield the identified high-TD classes. In that way, it enables identification and further experimentation of high-TD modules, without having to resort to a multitude of commercial and open source tools. Note : the source code of the TD Classifier frontend is also publicly available as part of the overall SDK4ED Dashboard and can be found here .","title":"Description"},{"location":"binary-classification-toolbox/#installation","text":"","title":"Installation"},{"location":"binary-classification-toolbox/#installation-using-anaconda","text":"In this section, we provide instructions on how the user can build the python Flask server of the TD Classifier from scratch, using the Anaconda virtual environment. The TD Classifier is developed to run on Unix and Windows systems with python 3.6.* innstalled. We suggest installing python via the Anaconda distribution as it provides an easy way to create a virtual environment and install dependencies. The configuration steps needed, are described below: Step 1 : Download the latest Anaconda distribution and follow the installation steps described in the Anaconda documentation . Step 2 : Open Anaconda cmd. Running Anaconda cmd activates the base environment. We need to create a specific environment to run TD Classifier backend. Create a new python 3.6.4 environment by running the following command: conda create --name td_classifier python=3.6.4 This command will result in the creation of a conda environment named td_classifier . In order to activate the new environment, execute the following command: conda activate td_classifier Step 3 : Once your newly created environment is active, install the needed libraries by executing the following commands: conda install -c anaconda numpy pandas scikit-learn waitress flask flask-cors requests pymongo conda install -c conda-forge gitpython and pip install pydriller Step 4 : To start the server, use the command promt inside the active environment and execute the commands described in section Run Server .","title":"Installation using Anaconda"},{"location":"binary-classification-toolbox/#installation-using-docker-recommended","text":"In this section, we provide instructions on how the user can build a new Docker Image that contains the python Flask app and the Conda environment of the of the TD Classifier. We highly recommend the users to select this way of installing the TD Classifier, as it constitutes the easiest way. Step 1 : Download and install Docker Step 2 : Clone the latest TD Classifier version and navigate to the home directory. You should see a DockerFile and a environment.yml file, which contains the Conda environment dependencies. Step 3 : In the home directory of the TD Classifier, open cmd and execute the following command: sudo docker build -t td_classifier_image . This command will result in the creation of a Docker Image named td_classifier_image . In order to create a Docker Container from this image, execute the following command: sudo docker run -it --name td_classifier_test -p 5005:5005 td_classifier_image This command will generate and run a Docker Container named td_classifier_test in interactive session mode, i.e. it will open a command promt inside the Container. - Step 4 : To start the server, use the command promt inside the running Container and execute the commands described in section Run Server .","title":"Installation using Docker (recommended)"},{"location":"binary-classification-toolbox/#installation-of-the-database","text":"A MongoDB database dedicated to storing the output of the TD Classifier web service allows the tool to quickly retrieve past results upon demand, without having to go through the time-consuming process of re-executing the analysis process. TD Classifier does not require a running database instance to be functional. However, in case you require access to previously produced results, a database dedicated to store the output of the TD Classifier web services might be of help. In that case, MongoDB is a well-suited option for the purposes of the TD Classifier. To quickly install a MongoDB using Docker, open cmd and execute the following command: sudo docker run --detach \\ -p 27017:27017 \\ --name mongodb \\ --volume /home/<user_name>/Desktop/mongo_data:/data/db \\ mongo This command will generate and run a MongoDB Docker Container named mongodb , which will serve as the TD Classifier's dedicated DB.","title":"Installation of the Database"},{"location":"binary-classification-toolbox/#run-server","text":"You can run the server in various modes using Python to run the td_classifier_service.py script: usage: td_classifier_service.py [-h] [-dh DB_HOST] [-dp DB_PORT] [-dn DB_DBNAME] [--debug] HOST PORT SERVER_MODE positional arguments: HOST Server HOST (e.g. \"localhost\") PORT Server PORT (e.g. \"5005\") SERVER_MODE builtin, waitress optional arguments: -h, --help show this help message and exit -dh DB_HOST MongoDB HOST (e.g. \"localhost\") (default: localhost) -dp DB_PORT MongoDB PORT (e.g. \"27017\") (default: 27017) -dn DB_DBNAME Database NAME (default: td_classifier_service) --debug Run builtin server in debug mode (default: False) HOST , PORT , and SERVER_MODE arguments are mandatory . You can set them according to your needs. DB_HOST , DB_PORT , and DB_DBNAME arguments are optional and assume that there is a MongoDB instance running either on a local machine or remotely. In case that there is no such MongoDB instance running, the TD Classifier will still return the results, but they will not be stored anywhere.","title":"Run Server"},{"location":"binary-classification-toolbox/#run-built-in-flask-server","text":"127.0.0.1:5005 Client <----------------> Flask To start the TD Classifier using the built-in Flask server, use the command promt inside the active Conda or Container environment and execute the following command: python td_classifier_service.py 0.0.0.0 5005 builtin --debug This command will start the built-in Flask server locally (0.0.0.0) on port 5005. MongoDB Integration In case there is a MongoDB instance running, use the command promt inside the active conda or Container environment and execute the following command: python td_classifier_service.py 0.0.0.0 5005 waitress -dh 160.40.52.130 -dp 27017 -dn td_classifier_service This command will start the built-in Flask server locally on port 5005 and store the results on a MongoDB database named \"td_classifier_service\" running locally on port 27017. Warning : The built-in Flask mode is useful for development since it has debugging enabled (e.g. in case of error the client gets a full stack trace). However, it is single-threaded. Do NOT use this mode in production!","title":"Run built-in Flask server"},{"location":"binary-classification-toolbox/#run-waitress-server","text":"127.0.0.1:5005 Client <----------------> Waitress <---> Flask To start the TD Classifier using the Waitress server, use the command promt inside the active Conda or Container environment and execute the following command: python td_classifier_service.py 0.0.0.0 5005 waitress This command will start the Waitress server locally (0.0.0.0) on port 5005. MongoDB Integration In case there is a MongoDB instance running, use the command promt inside the active conda or Container environment and execute the following command: python td_classifier_service.py 0.0.0.0 5005 waitress -dh 160.40.52.130 -dp 27017 -dn td_classifier_service This command will start the Waitress server locally on port 5000 and store the results on a MongoDB database named \"td_classifier_service\" running locally on port 27017. Warning : The Waitress mode is higly recommended in real production environments, since it supports scaling and multiple-request handling features.","title":"Run Waitress server"},{"location":"binary-classification-toolbox/#next-steps","text":"Once the server is up and running, you can either exploit the TD Classifier APIs directly via requests, or setup the SDK4ED platform locally (see here ) to benefit from the already implemented and user-friendly TD Classifier frontend.","title":"Next Steps"},{"location":"binary-classification-toolbox/#how-to-cite","text":"A paper introducing the TD Classifier tool has been published in the Proceedings of the International Conference on Technical Debt (TechDebt '22) . To cite this work, please use the following bibtex entry: @inproceedings{tsoukalas2022td, author = {Tsoukalas, Dimitrios and Chatzigeorgiou, Alexander and Ampatzoglou, Apostolos and Mittas, Nikolaos and Kehagias, Dionysios}, title = {TD Classifier: Automatic Identification of Java Classes with High Technical Debt}, year = {2022}, publisher = {Association for Computing Machinery}, address = {New York, NY, USA}, doi = {10.1145/3524843.3528094}, booktitle = {Proceedings of the International Conference on Technical Debt}, pages = {76\u201380}, numpages = {5}, location = {Pittsburgh, Pennsylvania}, series = {TechDebt '22} }","title":"How to cite?"},{"location":"forecasting-toolbox/","text":"Forecasting Toolbox Description This repository contains the source code of the Forecasting Toolbox back-end , which is part of the SDK4ED Platform . The purpose of the Forecasting Toolbox is to provide predictive forecasts regarding the evolution of the three core quality attributes targeted by the SDK4ED platform, namely Technical Debt , Energy and Dependability (Security) . The entry point of the Forecasting Toolbox is a RESTful web server that uses the Flask web framework wrapped inside Waitress , a Python WSGI production-ready server. At a lower level, the server exposes three sub-modules, implemented as individual web services. Each web service plays the role of an end-point that allows the invocation of a set of forecasting models and returns the results, providing users with insightful information for the future evolution each of the three core quality attributes of a software application. The services supported by the Forecasting Toolbox are listed below: - TD Forecaster : This web service is responsible for generating Technical Debt forecasts for a given software application. A TD forecast represents the predicted evolution of the total remediation effort (measured in minutes) to fix all code issues (e.g. code smells, bugs, code duplications, etc.) of a software application, up to a future point specified by the user. - Energy Forecaster : This web service is responsible for generating Energy forecasts for a given software application. An Energy forecast represents the predicted evolution of the total energy consumption (measured in Joules) of a software application, up to a future point specified by the user. - Dependability Forecaster : This web service is responsible for generating Security forecasts for a given software application. A Security forecast represents the predicted evolution of the Security Index (value between 0 and 1 that aggregates the entire program security characteristics) of a software application, up to a future point specified by the user. The three web services allow the individual and remote invocation of the forecasting models developed for estimating the evolution of TD, Energy and Security. This is achieved through the dedicated API exposed by the RESTful web server, which allows the user to perform simple HTTP GET requests to the three web services. Several inputs need to be provided as URL-encoded parameters to these requests. These parameters are listed below: Parameter Description Required Valid Inputs horizon The forecasting horizon up to which forecasts will be produced. Yes An integer in range [1-N], where N depends on the volume of data used to train the regressor. Currently there is no upper limit and the service returns an error if this value is set too high. project The project ID for which the forecasts will be produced. Yes A string value representing the ID of the selected project for which a forecast was requested. This ID is used to retrieve the TD, Energy and Dependability analysis metrics from the corresponding Toolboxes\u2019 DBs, which will then be used for forecasting model execution. Depending on the specific web service, this ID is constructed as follows: \u00b7 TD Forecaster: \u2018 : \u2019 \u00b7 Security Forecaster: \u2018 : \u2019 \u00b7 Energy Forecaster: \u2018 \u2019 Both and values are project properties retrieved from the SDK4ED Dashboard session storage. regressor The regressor model that will be used to produce forecasts. No One of the following string values: [\u2018auto\u2019, \u2018mlr\u2019, \u2018lasso\u2019, \u2018ridge\u2019, \u2018svr_linear\u2019, \u2018svr_rbf\u2019, \u2018random_forest\u2019, \u2018arima\u2019]. Default value is \u2018auto\u2019. If this parameter is omitted, default value is set to \u2018auto\u2019 and the service selects automatically the best model based on validation error minimization. ground_truth If the model will return also ground truth values or not. No One of the following string values: [\u2018yes\u2019, \u2018no\u2019]. Default value is \u2018no. test If the model will produce Train-Test or unseen forecasts. No One of the following string values: [\u2018yes\u2019, \u2018no\u2019]. Default value is \u2018no\u2019. If set to \u2018no\u2019, then the service uses the whole data to train a regressor and returns forecasts on unseen data. A value of \u2018yes\u2019 should be used only for model testing and not actual deployment into production. The output of the three individual web services provided by the Forecasting Toolbox, namely TD Forecaster, Energy Forecaster and Dependability Forecaster is a JSON file containing the predicted values for a particular quality attribute of the selected application. This JSON actually contains i) a status code of the response, ii) a N-size array containing the forecasts, where N is equal to the \u2018horizon\u2019 parameter, iii) a recap on the given parameter values, and iv) a message informing the user if the request was fulfilled successfully or not. Installation Installation using Anaconda In this section, we provide instructions on how the user can build the python Flask server of the Forecasting Toolbox from scratch, using the Anaconda virtual environment. The Forecasting Toolbox is developed to run on Unix and Windows systems with python 3.6.* innstalled. We suggest installing python via the Anaconda distribution as it provides an easy way to create a virtual environment and install dependencies. The configuration steps needed, are described below: Step 1 : Download the latest Anaconda distribution and follow the installation steps described in the Anaconda documentation . Step 2 : Open Anaconda cmd. Running Anaconda cmd activates the base environment. We need to create a specific environment to run Forecasting Toolbox. Create a new python 3.6.4 environment by running the following command: conda create --name forecaster_toolbox python=3.6.4 This command will result in the creation of a conda environment named forecaster_toolbox . In order to activate the new environment, execute the following command: conda activate forecaster_toolbox Step 3 : Once your newly created environment is active, install the needed libraries by executing the following commands: conda install -c anaconda numpy pandas scikit-learn waitress flask flask-cors pymongo and conda install -c saravji pmdarima Step 4 : To start the server, use the command promt inside the active environment and execute the commands described in section Run Server . Installation using Docker In this section, we provide instructions on how the user can build a new Docker Image that contains the python Flask app and the Conda environment of the of the Forecasting Toolbox. We highly recommend the users to select this way of installing the SDK4ED Forecasting Toolbox, as it constitutes the easiest way. Step 1 : Download and install Docker Step 2 : Clone the latest Forecasting Toolbox version and navigate to the home directory. You should see a DockerFile and a environment.yml file, which contains the Conda environment dependencies. Step 3 : In the home directory of the Forecasting Toolbox, open cmd and execute the following command: sudo docker build -t forecaster_toolbox . This command will result in the creation of a Docker Image named forecaster_toolbox . In order to create a Docker Container from this image, execute the following command: sudo docker run -it --name forecaster-toolbox-test -p 5000:5000 forecaster_toolbox This command will generate and run a Docker Container named forecaster-toolbox-test in interactive session mode, i.e. it will open a command promt inside the Container. - Step 4 : To start the server, use the command promt inside the running Container and execute the commands described in section Run Server . Installation of the Database Since the TD, Energy and Dependability forecasts are produced \"on the fly\", the Forecasting Toolbox does not require a running database instance to be functional. However, in case you require access to previously produced forecasting results, a database dedicated to store the output of the Forecasting web services might be of help. In that case, MongoDB is a well-suited option for the purposes of the Forecasting Toolbox. To quickly install a MongoDB using Docker, open cmd and execute the following command: sudo docker run --detach \\ -p 27017:27017 \\ --name mongodb \\ --volume /home/<user_name>/Desktop/mongo_data:/data/db \\ mongo This command will generate and run a MongoDB Docker Container named mongodb , which will serve as the Forecasting Toolbox dedicated DB. Run Server You can run the server in various modes using Python to run the forecaster_service.py script: usage: forecaster_service.py [-h] [-dh DB_HOST] [-dp DB_PORT] [-dn DB_DBNAME] [--debug] HOST PORT SERVER_MODE positional arguments: HOST Server HOST (e.g. \"localhost\") PORT Server PORT (e.g. \"5000\") SERVER_MODE builtin, waitress optional arguments: -h, --help show this help message and exit -dh DB_HOST MongoDB HOST (e.g. \"localhost\") (default: localhost) -dp DB_PORT MongoDB PORT (e.g. \"27017\") (default: 27017) -dn DB_DBNAME Database NAME (default: forecaster_service) --debug Run builtin server in debug mode (default: False) HOST , PORT , and SERVER_MODE arguments are mandatory . You can set them according to your needs. DB_HOST , DB_PORT , and DB_DBNAME arguments are optional and assume that there is a MongoDB instance running either on a local machine or remotely. In case that there is no such MongoDB instance running, the Forecasting Toolbox will still return the results, but they will not be stored anywhere. Run built-in Flask server 127.0.0.1:5000 Client <----------------> Flask To start the Forecasting Toolbox using the built-in Flask server, use the command promt inside the active Conda or Container environment and execute the following command: python forecaster_service.py 0.0.0.0 5000 builtin --debug This command will start the built-in Flask server locally (0.0.0.0) on port 5000. MongoDB Integration In case there is a MongoDB instance running, use the command promt inside the active conda or Container environment and execute the following command: python forecaster_service.py 0.0.0.0 5000 builtin -dh localhost -dp 27017 -dn forecaster_service --debug This command will start the built-in Flask server locally on port 5000 and store the results on a MongoDB database named \"forecaster_service\" running locally on port 27017. Warning : The built-in Flask mode is useful for development since it has debugging enabled (e.g. in case of error the client gets a full stack trace). However, it is single-threaded. Do NOT use this mode in production! Run Waitress server 127.0.0.1:5000 Client <----------------> Waitress <---> Flask To start the Forecasting Toolbox using the Waitress server, use the command promt inside the active Conda or Container environment and execute the following command: python forecaster_service.py 0.0.0.0 5000 waitress This command will start the Waitress server locally (0.0.0.0) on port 5000. MongoDB Integration In case there is a MongoDB instance running, use the command promt inside the active conda or Container environment and execute the following command: python forecaster_service.py 0.0.0.0 5000 waitress -dh localhost -dp 27017 -dn forecaster_service This command will start the Waitress server locally on port 5000 and store the results on a MongoDB database named \"forecaster_service\" running locally on port 27017. Warning : The Waitress mode is higly recommended in real production environments, since it supports scaling and multiple-request handling features. Run Tests A series of dedicated tests have been developed using the pytest framework in order to ensure the proper execution of the Forecasting Toolbox. Once the server is installed, the user can run the testing suite by opening a new command promt inside the active Conda or Container environment and executing the following command: pytest -v A list of results will start popping on the command prompt, informing the user whether a test has PASSED or FAILED. Usage Example Once the server is running, open your web browser and navigate to the following URL: http://127.0.0.1:5000/ForecasterToolbox/TDForecasting?horizon=5&project=apache_kafka&regressor=ridge&ground_truth=no&test=no You will get a JSON response containing TD forecasts of a sample application (Apache Kafka) for an horizon of 5 versions ahead, using the Ridge regressor model.","title":"Forecasting Toolbox"},{"location":"forecasting-toolbox/#forecasting-toolbox","text":"","title":"Forecasting Toolbox"},{"location":"forecasting-toolbox/#description","text":"This repository contains the source code of the Forecasting Toolbox back-end , which is part of the SDK4ED Platform . The purpose of the Forecasting Toolbox is to provide predictive forecasts regarding the evolution of the three core quality attributes targeted by the SDK4ED platform, namely Technical Debt , Energy and Dependability (Security) . The entry point of the Forecasting Toolbox is a RESTful web server that uses the Flask web framework wrapped inside Waitress , a Python WSGI production-ready server. At a lower level, the server exposes three sub-modules, implemented as individual web services. Each web service plays the role of an end-point that allows the invocation of a set of forecasting models and returns the results, providing users with insightful information for the future evolution each of the three core quality attributes of a software application. The services supported by the Forecasting Toolbox are listed below: - TD Forecaster : This web service is responsible for generating Technical Debt forecasts for a given software application. A TD forecast represents the predicted evolution of the total remediation effort (measured in minutes) to fix all code issues (e.g. code smells, bugs, code duplications, etc.) of a software application, up to a future point specified by the user. - Energy Forecaster : This web service is responsible for generating Energy forecasts for a given software application. An Energy forecast represents the predicted evolution of the total energy consumption (measured in Joules) of a software application, up to a future point specified by the user. - Dependability Forecaster : This web service is responsible for generating Security forecasts for a given software application. A Security forecast represents the predicted evolution of the Security Index (value between 0 and 1 that aggregates the entire program security characteristics) of a software application, up to a future point specified by the user. The three web services allow the individual and remote invocation of the forecasting models developed for estimating the evolution of TD, Energy and Security. This is achieved through the dedicated API exposed by the RESTful web server, which allows the user to perform simple HTTP GET requests to the three web services. Several inputs need to be provided as URL-encoded parameters to these requests. These parameters are listed below: Parameter Description Required Valid Inputs horizon The forecasting horizon up to which forecasts will be produced. Yes An integer in range [1-N], where N depends on the volume of data used to train the regressor. Currently there is no upper limit and the service returns an error if this value is set too high. project The project ID for which the forecasts will be produced. Yes A string value representing the ID of the selected project for which a forecast was requested. This ID is used to retrieve the TD, Energy and Dependability analysis metrics from the corresponding Toolboxes\u2019 DBs, which will then be used for forecasting model execution. Depending on the specific web service, this ID is constructed as follows: \u00b7 TD Forecaster: \u2018 : \u2019 \u00b7 Security Forecaster: \u2018 : \u2019 \u00b7 Energy Forecaster: \u2018 \u2019 Both and values are project properties retrieved from the SDK4ED Dashboard session storage. regressor The regressor model that will be used to produce forecasts. No One of the following string values: [\u2018auto\u2019, \u2018mlr\u2019, \u2018lasso\u2019, \u2018ridge\u2019, \u2018svr_linear\u2019, \u2018svr_rbf\u2019, \u2018random_forest\u2019, \u2018arima\u2019]. Default value is \u2018auto\u2019. If this parameter is omitted, default value is set to \u2018auto\u2019 and the service selects automatically the best model based on validation error minimization. ground_truth If the model will return also ground truth values or not. No One of the following string values: [\u2018yes\u2019, \u2018no\u2019]. Default value is \u2018no. test If the model will produce Train-Test or unseen forecasts. No One of the following string values: [\u2018yes\u2019, \u2018no\u2019]. Default value is \u2018no\u2019. If set to \u2018no\u2019, then the service uses the whole data to train a regressor and returns forecasts on unseen data. A value of \u2018yes\u2019 should be used only for model testing and not actual deployment into production. The output of the three individual web services provided by the Forecasting Toolbox, namely TD Forecaster, Energy Forecaster and Dependability Forecaster is a JSON file containing the predicted values for a particular quality attribute of the selected application. This JSON actually contains i) a status code of the response, ii) a N-size array containing the forecasts, where N is equal to the \u2018horizon\u2019 parameter, iii) a recap on the given parameter values, and iv) a message informing the user if the request was fulfilled successfully or not.","title":"Description"},{"location":"forecasting-toolbox/#installation","text":"","title":"Installation"},{"location":"forecasting-toolbox/#installation-using-anaconda","text":"In this section, we provide instructions on how the user can build the python Flask server of the Forecasting Toolbox from scratch, using the Anaconda virtual environment. The Forecasting Toolbox is developed to run on Unix and Windows systems with python 3.6.* innstalled. We suggest installing python via the Anaconda distribution as it provides an easy way to create a virtual environment and install dependencies. The configuration steps needed, are described below: Step 1 : Download the latest Anaconda distribution and follow the installation steps described in the Anaconda documentation . Step 2 : Open Anaconda cmd. Running Anaconda cmd activates the base environment. We need to create a specific environment to run Forecasting Toolbox. Create a new python 3.6.4 environment by running the following command: conda create --name forecaster_toolbox python=3.6.4 This command will result in the creation of a conda environment named forecaster_toolbox . In order to activate the new environment, execute the following command: conda activate forecaster_toolbox Step 3 : Once your newly created environment is active, install the needed libraries by executing the following commands: conda install -c anaconda numpy pandas scikit-learn waitress flask flask-cors pymongo and conda install -c saravji pmdarima Step 4 : To start the server, use the command promt inside the active environment and execute the commands described in section Run Server .","title":"Installation using Anaconda"},{"location":"forecasting-toolbox/#installation-using-docker","text":"In this section, we provide instructions on how the user can build a new Docker Image that contains the python Flask app and the Conda environment of the of the Forecasting Toolbox. We highly recommend the users to select this way of installing the SDK4ED Forecasting Toolbox, as it constitutes the easiest way. Step 1 : Download and install Docker Step 2 : Clone the latest Forecasting Toolbox version and navigate to the home directory. You should see a DockerFile and a environment.yml file, which contains the Conda environment dependencies. Step 3 : In the home directory of the Forecasting Toolbox, open cmd and execute the following command: sudo docker build -t forecaster_toolbox . This command will result in the creation of a Docker Image named forecaster_toolbox . In order to create a Docker Container from this image, execute the following command: sudo docker run -it --name forecaster-toolbox-test -p 5000:5000 forecaster_toolbox This command will generate and run a Docker Container named forecaster-toolbox-test in interactive session mode, i.e. it will open a command promt inside the Container. - Step 4 : To start the server, use the command promt inside the running Container and execute the commands described in section Run Server .","title":"Installation using Docker"},{"location":"forecasting-toolbox/#installation-of-the-database","text":"Since the TD, Energy and Dependability forecasts are produced \"on the fly\", the Forecasting Toolbox does not require a running database instance to be functional. However, in case you require access to previously produced forecasting results, a database dedicated to store the output of the Forecasting web services might be of help. In that case, MongoDB is a well-suited option for the purposes of the Forecasting Toolbox. To quickly install a MongoDB using Docker, open cmd and execute the following command: sudo docker run --detach \\ -p 27017:27017 \\ --name mongodb \\ --volume /home/<user_name>/Desktop/mongo_data:/data/db \\ mongo This command will generate and run a MongoDB Docker Container named mongodb , which will serve as the Forecasting Toolbox dedicated DB.","title":"Installation of the Database"},{"location":"forecasting-toolbox/#run-server","text":"You can run the server in various modes using Python to run the forecaster_service.py script: usage: forecaster_service.py [-h] [-dh DB_HOST] [-dp DB_PORT] [-dn DB_DBNAME] [--debug] HOST PORT SERVER_MODE positional arguments: HOST Server HOST (e.g. \"localhost\") PORT Server PORT (e.g. \"5000\") SERVER_MODE builtin, waitress optional arguments: -h, --help show this help message and exit -dh DB_HOST MongoDB HOST (e.g. \"localhost\") (default: localhost) -dp DB_PORT MongoDB PORT (e.g. \"27017\") (default: 27017) -dn DB_DBNAME Database NAME (default: forecaster_service) --debug Run builtin server in debug mode (default: False) HOST , PORT , and SERVER_MODE arguments are mandatory . You can set them according to your needs. DB_HOST , DB_PORT , and DB_DBNAME arguments are optional and assume that there is a MongoDB instance running either on a local machine or remotely. In case that there is no such MongoDB instance running, the Forecasting Toolbox will still return the results, but they will not be stored anywhere.","title":"Run Server"},{"location":"forecasting-toolbox/#run-built-in-flask-server","text":"127.0.0.1:5000 Client <----------------> Flask To start the Forecasting Toolbox using the built-in Flask server, use the command promt inside the active Conda or Container environment and execute the following command: python forecaster_service.py 0.0.0.0 5000 builtin --debug This command will start the built-in Flask server locally (0.0.0.0) on port 5000. MongoDB Integration In case there is a MongoDB instance running, use the command promt inside the active conda or Container environment and execute the following command: python forecaster_service.py 0.0.0.0 5000 builtin -dh localhost -dp 27017 -dn forecaster_service --debug This command will start the built-in Flask server locally on port 5000 and store the results on a MongoDB database named \"forecaster_service\" running locally on port 27017. Warning : The built-in Flask mode is useful for development since it has debugging enabled (e.g. in case of error the client gets a full stack trace). However, it is single-threaded. Do NOT use this mode in production!","title":"Run built-in Flask server"},{"location":"forecasting-toolbox/#run-waitress-server","text":"127.0.0.1:5000 Client <----------------> Waitress <---> Flask To start the Forecasting Toolbox using the Waitress server, use the command promt inside the active Conda or Container environment and execute the following command: python forecaster_service.py 0.0.0.0 5000 waitress This command will start the Waitress server locally (0.0.0.0) on port 5000. MongoDB Integration In case there is a MongoDB instance running, use the command promt inside the active conda or Container environment and execute the following command: python forecaster_service.py 0.0.0.0 5000 waitress -dh localhost -dp 27017 -dn forecaster_service This command will start the Waitress server locally on port 5000 and store the results on a MongoDB database named \"forecaster_service\" running locally on port 27017. Warning : The Waitress mode is higly recommended in real production environments, since it supports scaling and multiple-request handling features.","title":"Run Waitress server"},{"location":"forecasting-toolbox/#run-tests","text":"A series of dedicated tests have been developed using the pytest framework in order to ensure the proper execution of the Forecasting Toolbox. Once the server is installed, the user can run the testing suite by opening a new command promt inside the active Conda or Container environment and executing the following command: pytest -v A list of results will start popping on the command prompt, informing the user whether a test has PASSED or FAILED.","title":"Run Tests"},{"location":"forecasting-toolbox/#usage","text":"","title":"Usage"},{"location":"forecasting-toolbox/#example","text":"Once the server is running, open your web browser and navigate to the following URL: http://127.0.0.1:5000/ForecasterToolbox/TDForecasting?horizon=5&project=apache_kafka&regressor=ridge&ground_truth=no&test=no You will get a JSON response containing TD forecasts of a sample application (Apache Kafka) for an horizon of 5 versions ahead, using the Ridge regressor model.","title":"Example"},{"location":"predictive-models-toolbox/","text":"CRISSPAC Coronary artery disease RIsk-stratification Syntax Score Predictive Algorithm Calculator Description CRISSPAC: Coronary artery disease RIsk-stratification Syntax Score Predictive Algorithm Calculator Installation The development of the platform is based on the open-source statistical programming language R and the R shiny framework. Users will need to download R in order to use CRISSPAC and we suggest the use of RStudio. All required code can be found in this GitHub repository. Required software R version (minimal version 4.1.1) Rstudio (minimal version 2021.09.0 Build 351) (optional) List of required R packages (with their dependencies) R package Version dplyr 1.0.7 DT 0.19 Formula 1.2-4 ggbeeswarm 0.6.0 ggExtra 0.9 ggplot2 3.3.6 ggthemes 4.2.4 Hmisc 4.5-0 lattice 0.20-44 psych 2.1.9 randomForest 4.6-14 readxl 1.3.1 reshape2 1.4.4 shiny 1.6.0 shinydashboard 0.7.1 shinyjs 2.0.0 survival 3.2-11 tidyr 1.1.3 Input CRISSPAC uses the Electronic Health Records (EHRs) collected during the GESS study (GESS trial, ClinicalTrials.gov Identifier: NCT03150680). Regarding this, five types of EHRs (see Appendix) with seventy-two measured risk factors are the main input of the platform. Usage To initiate CRISSPAC, simply run the file server.R from Rstudio (or RGUI). Minimal data are contained in the source code of the package. For more detailed examples please have a look at the journal publication. Reference Mittas, N., Chatzopoulou, F., Kyritsis, K. A., Papagiannopoulos, C. I., Theodoroula, N. F., Papazoglou, A. S., ... & Vizirianakis, I. S. (2021). A Risk-Stratification Machine Learning Framework for the Prediction of Coronary Artery Disease Severity: Insights from the GESS Trial. Frontiers in cardiovascular medicine, 8. Appendix Electronic Health Record Risk factor Description Type Levels History HYPERTENSION History of hypertension Categorical No/Yes History DIABETES MELLITUS History of diabetes mellitus Categorical No/Yes History DYSLIPIDAEMIA History of dyslipidaemia Categorical No/Yes History (+) FAMILY HISTORY Positive (+) family history of CAD Categorical No/Yes History SMOKING History of smoking Categorical No/Yes History PREVIOUS STROKE Previous stroke Categorical No/Yes History CHRONIC KIDNEY FAILURE History of chronic kidney disease Categorical No/Yes History PERIPHERAL VASCULAR DISEASE History of peripheral vascular disease Categorical No/Yes History AORTIC ANEURYSMS History of aortic aneurysms Categorical No/Yes History CHRONIC PULMONARY OBSTRUCTIVE DISEASE History of chronic pulmonary obstructive disease Categorical No/Yes History AUTOIMMUNE DISEASE History of any autoimmune disease Categorical No/Yes History ATRIAL FIBRILLATION History of atrial fibrillation Categorical No/Yes History AGE Age of patient (in years) Numeric - Entry CHEST PAIN Chest pain Categorical No/Yes Entry DYSPNEA Dyspnea Categorical No/Yes Entry EASY FATIGUE Easy fatigue Categorical No/Yes Entry ST-T CHANGES ST-T changes Categorical No/Yes Entry Q wave in ECG Q wave on the electrocardiogram Categorical No/Yes Entry BMI Body mass index (kg/m2) Numeric - Entry BPM Beats per minute (heart rate) Numeric - Entry SAP Systolic arterial pressure (SAP) (mmHg) Numeric - Entry DAP Diastolic arterial pressure (DAP) (mmHg) Numeric - Entry CRUSADE SCORE Crusade score Categorical No/Yes Entry GRACE SCORE Grace score Categorical No/Yes Entry QRS DURATION ms Body mass index (kg/m2) Numeric - Biochemical GFR Glomerular filtration rate by CKD-EPI (mL/min/1.73m2) Numeric - Biochemical GLU Glucose (mg/dL) Numeric - Biochemical UREA Urea (mg/dL) Numeric - Biochemical CREATININE Creatinine (mg/dL) Numeric - Biochemical URIC ACID Uric acid (mg/dL) Numeric - Biochemical CHOL Total cholesterol (mg/dL) Numeric - Biochemical TG Triglycerides (mg/dL) Numeric - Biochemical HDL High density lipoprotein cholesterol (mg/dL) Numeric - Biochemical LDL Low density lipoprotein cholesterol (mg/dL) Numeric - Biochemical TNT-HS High sensitivity cardiac troponin (ng/L) Numeric - Biochemical SGOT Aspartate aminotransferase (units/L) Numeric - Biochemical SGPT Alanine aminotransferase (units/L) Numeric - Biochemical LDH Lactic acid dehydrogenase (units/L) Numeric - Biochemical CPK Creatine phosphokinase (units/L) Numeric - Biochemical NA Sodium (mEq/L) Numeric - Biochemical K Potassium (mmol/L) Numeric - Biochemical INR International normalized ratio Numeric - Complete Blood Count WBC White blood cells (*1000) Numeric - Complete Blood Count NEU% Neutrophils percentage Numeric - Complete Blood Count LYM% Lymphocytes percentage Numeric - Complete Blood Count MONO% Monocytes percentage Numeric - Complete Blood Count EOS% Eosinophils percentage Numeric - Complete Blood Count BASO% Basophils percentage Numeric - Complete Blood Count RBC Red blood cells (*1000000) Numeric - Complete Blood Count HGB Hemoglobin (g/dL) Numeric - Complete Blood Count HCT Hematocrit percentage Numeric - Complete Blood Count MCV Mean corpuscular volume (fl) Numeric - Complete Blood Count MCH Mean corpuscular hemoglobin (pg) Numeric - Complete Blood Count MCHC Mean corpuscular hemoglobin concentration (g/dL) Numeric - Complete Blood Count RDW-CV Red blood cell distribution width- coefficient of variation (percentage) Numeric - Complete Blood Count RDW-SD Red blood cell distribution width- standard deviation (percentage) Numeric - Complete Blood Count PLT Platelets (\uf02a1000) Numeric - Complete Blood Count MPV Mean platelet volume (fl) Numeric - Complete Blood Count PDW Platelet distribution width (percentage) Numeric - Complete Blood Count PCT Plateletcrit (percentage) Numeric - Complete Blood Count P-LCR Platelet-large cell ratio Numeric - Differential ACS Acute coronary syndrome Categorical No/Yes Differential NSTEMI Non-ST-elevated myocardial infarction Categorical No/Yes Differential STEMI ST-elevated myocardial infraction Categorical No/Yes Differential UNSTABLE ANGINA Unstable angina Categorical No/Yes Differential STABLE ANGINA Stable angina Categorical No/Yes Differential SPECT Pathological single-photon emission computerized tomography results Categorical No/Yes Differential CCTA Pathological coronary computed tomography angiography results Categorical No/Yes Differential THORACIC PAIN Thoracic pain Categorical No/Yes Differential CHRONIC CORONARY SYNDROME Chronic coronary syndrome Categorical No/Yes Differential AORTIC VALVE STENOSIS Severe aortic stenosis Categorical No/Yes Differential HEART FAILURE Heart failure Categorical No/Yes","title":"CRISSPAC"},{"location":"predictive-models-toolbox/#crisspac","text":"Coronary artery disease RIsk-stratification Syntax Score Predictive Algorithm Calculator","title":"CRISSPAC"},{"location":"predictive-models-toolbox/#description","text":"CRISSPAC: Coronary artery disease RIsk-stratification Syntax Score Predictive Algorithm Calculator","title":"Description"},{"location":"predictive-models-toolbox/#installation","text":"The development of the platform is based on the open-source statistical programming language R and the R shiny framework. Users will need to download R in order to use CRISSPAC and we suggest the use of RStudio. All required code can be found in this GitHub repository. Required software R version (minimal version 4.1.1) Rstudio (minimal version 2021.09.0 Build 351) (optional) List of required R packages (with their dependencies) R package Version dplyr 1.0.7 DT 0.19 Formula 1.2-4 ggbeeswarm 0.6.0 ggExtra 0.9 ggplot2 3.3.6 ggthemes 4.2.4 Hmisc 4.5-0 lattice 0.20-44 psych 2.1.9 randomForest 4.6-14 readxl 1.3.1 reshape2 1.4.4 shiny 1.6.0 shinydashboard 0.7.1 shinyjs 2.0.0 survival 3.2-11 tidyr 1.1.3","title":"Installation"},{"location":"predictive-models-toolbox/#input","text":"CRISSPAC uses the Electronic Health Records (EHRs) collected during the GESS study (GESS trial, ClinicalTrials.gov Identifier: NCT03150680). Regarding this, five types of EHRs (see Appendix) with seventy-two measured risk factors are the main input of the platform.","title":"Input"},{"location":"predictive-models-toolbox/#usage","text":"To initiate CRISSPAC, simply run the file server.R from Rstudio (or RGUI). Minimal data are contained in the source code of the package. For more detailed examples please have a look at the journal publication.","title":"Usage"},{"location":"predictive-models-toolbox/#reference","text":"Mittas, N., Chatzopoulou, F., Kyritsis, K. A., Papagiannopoulos, C. I., Theodoroula, N. F., Papazoglou, A. S., ... & Vizirianakis, I. S. (2021). A Risk-Stratification Machine Learning Framework for the Prediction of Coronary Artery Disease Severity: Insights from the GESS Trial. Frontiers in cardiovascular medicine, 8.","title":"Reference"},{"location":"predictive-models-toolbox/#appendix","text":"Electronic Health Record Risk factor Description Type Levels History HYPERTENSION History of hypertension Categorical No/Yes History DIABETES MELLITUS History of diabetes mellitus Categorical No/Yes History DYSLIPIDAEMIA History of dyslipidaemia Categorical No/Yes History (+) FAMILY HISTORY Positive (+) family history of CAD Categorical No/Yes History SMOKING History of smoking Categorical No/Yes History PREVIOUS STROKE Previous stroke Categorical No/Yes History CHRONIC KIDNEY FAILURE History of chronic kidney disease Categorical No/Yes History PERIPHERAL VASCULAR DISEASE History of peripheral vascular disease Categorical No/Yes History AORTIC ANEURYSMS History of aortic aneurysms Categorical No/Yes History CHRONIC PULMONARY OBSTRUCTIVE DISEASE History of chronic pulmonary obstructive disease Categorical No/Yes History AUTOIMMUNE DISEASE History of any autoimmune disease Categorical No/Yes History ATRIAL FIBRILLATION History of atrial fibrillation Categorical No/Yes History AGE Age of patient (in years) Numeric - Entry CHEST PAIN Chest pain Categorical No/Yes Entry DYSPNEA Dyspnea Categorical No/Yes Entry EASY FATIGUE Easy fatigue Categorical No/Yes Entry ST-T CHANGES ST-T changes Categorical No/Yes Entry Q wave in ECG Q wave on the electrocardiogram Categorical No/Yes Entry BMI Body mass index (kg/m2) Numeric - Entry BPM Beats per minute (heart rate) Numeric - Entry SAP Systolic arterial pressure (SAP) (mmHg) Numeric - Entry DAP Diastolic arterial pressure (DAP) (mmHg) Numeric - Entry CRUSADE SCORE Crusade score Categorical No/Yes Entry GRACE SCORE Grace score Categorical No/Yes Entry QRS DURATION ms Body mass index (kg/m2) Numeric - Biochemical GFR Glomerular filtration rate by CKD-EPI (mL/min/1.73m2) Numeric - Biochemical GLU Glucose (mg/dL) Numeric - Biochemical UREA Urea (mg/dL) Numeric - Biochemical CREATININE Creatinine (mg/dL) Numeric - Biochemical URIC ACID Uric acid (mg/dL) Numeric - Biochemical CHOL Total cholesterol (mg/dL) Numeric - Biochemical TG Triglycerides (mg/dL) Numeric - Biochemical HDL High density lipoprotein cholesterol (mg/dL) Numeric - Biochemical LDL Low density lipoprotein cholesterol (mg/dL) Numeric - Biochemical TNT-HS High sensitivity cardiac troponin (ng/L) Numeric - Biochemical SGOT Aspartate aminotransferase (units/L) Numeric - Biochemical SGPT Alanine aminotransferase (units/L) Numeric - Biochemical LDH Lactic acid dehydrogenase (units/L) Numeric - Biochemical CPK Creatine phosphokinase (units/L) Numeric - Biochemical NA Sodium (mEq/L) Numeric - Biochemical K Potassium (mmol/L) Numeric - Biochemical INR International normalized ratio Numeric - Complete Blood Count WBC White blood cells (*1000) Numeric - Complete Blood Count NEU% Neutrophils percentage Numeric - Complete Blood Count LYM% Lymphocytes percentage Numeric - Complete Blood Count MONO% Monocytes percentage Numeric - Complete Blood Count EOS% Eosinophils percentage Numeric - Complete Blood Count BASO% Basophils percentage Numeric - Complete Blood Count RBC Red blood cells (*1000000) Numeric - Complete Blood Count HGB Hemoglobin (g/dL) Numeric - Complete Blood Count HCT Hematocrit percentage Numeric - Complete Blood Count MCV Mean corpuscular volume (fl) Numeric - Complete Blood Count MCH Mean corpuscular hemoglobin (pg) Numeric - Complete Blood Count MCHC Mean corpuscular hemoglobin concentration (g/dL) Numeric - Complete Blood Count RDW-CV Red blood cell distribution width- coefficient of variation (percentage) Numeric - Complete Blood Count RDW-SD Red blood cell distribution width- standard deviation (percentage) Numeric - Complete Blood Count PLT Platelets (\uf02a1000) Numeric - Complete Blood Count MPV Mean platelet volume (fl) Numeric - Complete Blood Count PDW Platelet distribution width (percentage) Numeric - Complete Blood Count PCT Plateletcrit (percentage) Numeric - Complete Blood Count P-LCR Platelet-large cell ratio Numeric - Differential ACS Acute coronary syndrome Categorical No/Yes Differential NSTEMI Non-ST-elevated myocardial infarction Categorical No/Yes Differential STEMI ST-elevated myocardial infraction Categorical No/Yes Differential UNSTABLE ANGINA Unstable angina Categorical No/Yes Differential STABLE ANGINA Stable angina Categorical No/Yes Differential SPECT Pathological single-photon emission computerized tomography results Categorical No/Yes Differential CCTA Pathological coronary computed tomography angiography results Categorical No/Yes Differential THORACIC PAIN Thoracic pain Categorical No/Yes Differential CHRONIC CORONARY SYNDROME Chronic coronary syndrome Categorical No/Yes Differential AORTIC VALVE STENOSIS Severe aortic stenosis Categorical No/Yes Differential HEART FAILURE Heart failure Categorical No/Yes","title":"Appendix"},{"location":"shap-boruta/","text":"SHAP-Boruta The present work aims to provide a model-agnostic analysis towards explaining decisions made by the complex TD classification framework proposed in our previous related study , in order to make the entire decision-making process transparent. To this end, by constructing accurate project-specific classifiers for 22 software projects, we exploit the SHAP model explainability method to extract feature importance ranks and interpret the effect that various software metrics have on labeling a software class as high-TD. Subsequently, given a list of ranked important features (i.e., metrics) per each project, we investigate whether the top important metrics (as extracted by SHAP analysis) agree among projects with similar characteristics. Finally, through the features\u2019 global interpretation that SHAP analysis inherently supports, we extract metric thresholds (heuristic values) that may act as practical TD prevention guidelines (or rules of thumb) for developers.","title":"SHAP-Boruta"},{"location":"shap-boruta/#shap-boruta","text":"The present work aims to provide a model-agnostic analysis towards explaining decisions made by the complex TD classification framework proposed in our previous related study , in order to make the entire decision-making process transparent. To this end, by constructing accurate project-specific classifiers for 22 software projects, we exploit the SHAP model explainability method to extract feature importance ranks and interpret the effect that various software metrics have on labeling a software class as high-TD. Subsequently, given a list of ranked important features (i.e., metrics) per each project, we investigate whether the top important metrics (as extracted by SHAP analysis) agree among projects with similar characteristics. Finally, through the features\u2019 global interpretation that SHAP analysis inherently supports, we extract metric thresholds (heuristic values) that may act as practical TD prevention guidelines (or rules of thumb) for developers.","title":"SHAP-Boruta"}]}